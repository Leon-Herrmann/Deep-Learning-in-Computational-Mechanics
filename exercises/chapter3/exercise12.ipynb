{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Exercise 12 - Learning Strain Distributions\n",
    "### Task\n",
    "Tune an advanced neural network to learn strain distributions\n",
    "- Perform a training with the tensorBoard options (`writeGraph`, `writeHistogram`, `writeLearningHistory`, `writePredictions`) enabled\n",
    "- Invoke TensorBoard with `tensorboard --logdir=logs` in the terminal (while being in the same directory as this notebook). Open TensorBoard with the provided link of the form http://localhost:6006\n",
    "- Compare the performance of the three neural network architectures by changing `selectNN` and using TensorBoard (in the `scalars` menu, make sure to toggle the y-axis log scale)\n",
    "- Tune the hyperparameters (turn off the `writeHistogram` and `writePredictions`)\n",
    "- Increase the number of training samples with `numberOfTrainingSamples` and readjust the hyperparameters if necessary\n",
    "- Add L2 regularization with `weightDecay`\n",
    "\n",
    "### Learning goals\n",
    "- Understanding the process of hyperparameter tuning\n",
    "- Familiarzing yourself with professional deep learning training workflows with tools, such as DataSet, DataLoader, summary, and TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import NeuralNetwork\n",
    "import datetime\n",
    "import copy\n",
    "import torchvision"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorBoard options"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "writeGraph = False\n",
    "writeHistogram = False\n",
    "writeLearningHistory = False\n",
    "writePredictions = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "driver setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "seed = 2\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter(log_dir=\"./logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network architecture selection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "selectNN = 2  # 0 for UNet, 1 for sequential CNN, 2 for UNet with subsequent feedforward CNN"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "kernelSize = 3\n",
    "\n",
    "if selectNN == 0:\n",
    "    channels = [1, 32, 64]\n",
    "    channelsOut = 3\n",
    "    numberOfConvolutionsPerBlock = 1\n",
    "    model = NeuralNetwork.UNet(channels, channelsOut, numberOfConvolutionsPerBlock, kernelSize)\n",
    "elif selectNN == 1:\n",
    "    channels = [1, 32, 64, 32]\n",
    "    channelsOut = 3\n",
    "    model = NeuralNetwork.FeedforwardCNN(channels, channelsOut, kernelSize)\n",
    "elif selectNN == 2:\n",
    "    channelsUNet = [1, 32, 64]\n",
    "    numberOfConvolutionsPerBlockUNet = 1\n",
    "    channelsFeedforwardCNN = [64, 32, 16]\n",
    "    channelsOut = 3\n",
    "    model = NeuralNetwork.UNetWithSubsequentFeedforwardCNN(channelsUNet, numberOfConvolutionsPerBlockUNet,\n",
    "                                                           channelsFeedforwardCNN, channelsOut, kernelSize)\n",
    "model.to(device)\n",
    "summary(model, (1, 32, 32))\n",
    "if writeGraph == True:\n",
    "    writer.add_graph(model, torch.randn((1, 1, 32, 32), device=device))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "batchSize = 128\n",
    "alpha = -0.2\n",
    "beta = 0.2\n",
    "weightDecay = 0\n",
    "lr = 2e-3\n",
    "epochs = 4000\n",
    "earlyStopping = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "numberOfTrainingSamples = 1\n",
    "numberOfSamples = numberOfTrainingSamples + 32\n",
    "dataset = NeuralNetwork.elasticityDataset(device, numberOfSamples)\n",
    "# normalization\n",
    "dataset.E = (dataset.E - np.mean([3000, 85000])) / np.std([3000, 85000])\n",
    "datasetTraining, datasetValidation = torch.utils.data.random_split(dataset, [numberOfTrainingSamples,\n",
    "                                                                             len(dataset) - numberOfTrainingSamples],\n",
    "                                                                   generator=torch.Generator().manual_seed(2))\n",
    "\n",
    "dataloaderTraining = DataLoader(datasetTraining, batch_size=batchSize)\n",
    "dataloaderValidation = DataLoader(datasetValidation, batch_size=len(dataset))\n",
    "\n",
    "if writePredictions == True:\n",
    "    sample = next(iter(dataloaderValidation))\n",
    "    validationLabelImages = torchvision.utils.make_grid(sample[1][:16], normalize=True, value_range=(-1, 1))\n",
    "    for i in range(3):\n",
    "        writer.add_image(f'validation label {i + 1}', validationLabelImages[i], dataformats='HW')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer and scheduler instantiation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weightDecay)\n",
    "lr_lambda = lambda epoch: (beta * epoch + 1) ** alpha\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "trainingCostHistory = np.zeros(epochs)\n",
    "validationCostHistory = np.zeros(epochs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "start = time.perf_counter()\n",
    "start0 = start\n",
    "bestCost = 1e10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if writeHistogram == True:\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param, epoch)\n",
    "\n",
    "    model.train()\n",
    "    for batch, sample in enumerate(dataloaderTraining):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(sample[0])\n",
    "        cost = NeuralNetwork.costFunction(prediction, sample[1])\n",
    "\n",
    "        trainingCostHistory[epoch] += cost.detach() * len(sample[1])\n",
    "\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    trainingCostHistory[epoch] /= numberOfTrainingSamples\n",
    "    scheduler.step()\n",
    "    if writeHistogram == True:\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    sample = next(iter(dataloaderValidation))\n",
    "    with torch.no_grad():\n",
    "        prediction = model(sample[0])\n",
    "        cost = NeuralNetwork.costFunction(prediction, sample[1])\n",
    "\n",
    "        validationCostHistory[epoch] = cost\n",
    "        if validationCostHistory[epoch] < bestCost:\n",
    "            modelParametersBest = copy.deepcopy(model.state_dict())\n",
    "            bestCost = validationCostHistory[epoch]\n",
    "\n",
    "        if writePredictions == True:\n",
    "            validationPredictionImages = torchvision.utils.make_grid(prediction[:16], normalize=True,\n",
    "                                                                     value_range=(-1, 1))\n",
    "            for i in range(3):\n",
    "                writer.add_image(f'validation prediction {i + 1}', validationPredictionImages[i], epoch,\n",
    "                                 dataformats='HW')\n",
    "\n",
    "    elapsedTime = time.perf_counter() - start\n",
    "    if epoch % 10 == 0:\n",
    "        string = \"Epoch: {}/{}\\t\\tTraining cost: {:.2e}\\t\\tValidation cost: {:.2e}\\nElapsed time for last epoch: {:.2f} s\"\n",
    "        print(string.format(epoch + 1, epochs, trainingCostHistory[epoch], validationCostHistory[epoch], elapsedTime))\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    if writeLearningHistory == True:\n",
    "        writer.add_scalar('training_loss', trainingCostHistory[epoch], epoch)\n",
    "        writer.add_scalar('validation_loss', validationCostHistory[epoch], epoch)\n",
    "\n",
    "if earlyStopping == True:\n",
    "    model.load_state_dict(modelParametersBest)\n",
    "print(\"Total elapsed time during training: {:.2f} s\".format(time.perf_counter() - start0))\n",
    "writer.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning history"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainingCostHistory, 'k', label='training')\n",
    "ax.plot(validationCostHistory, 'r', label='validation')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('cost')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction of training sample"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "component = 0\n",
    "sample = next(iter(dataloaderTraining))\n",
    "\n",
    "if numberOfTrainingSamples < 4:  # necessary as the batch normalization parameters are not tuned well enough with so few samples\n",
    "    model.eval()  # ensures that the batch normalization does not continue learning from input data\n",
    "else:\n",
    "    model.train()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(model(sample[0])[0, component].detach().cpu(), cmap=plt.cm.jet)\n",
    "ax[0].set_title('prediction')\n",
    "ax[1].imshow(sample[1][0, component].detach().cpu(), cmap=plt.cm.jet)\n",
    "ax[1].set_title('ground truth')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction of validation sample"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "component = 0\n",
    "sample = next(iter(dataloaderValidation))\n",
    "\n",
    "model.eval()  # ensures that the batch normalization does not continue learning from input data\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(model(sample[0])[0, component].detach().cpu(), cmap=plt.cm.jet)\n",
    "ax[0].set_title('prediction')\n",
    "ax[1].imshow(sample[1][0, component].detach().cpu(), cmap=plt.cm.jet)\n",
    "ax[1].set_title('ground truth')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
