{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 Solution - Linear Regression\n",
    "\n",
    "### Task\n",
    "Implement a linear regression model with the provided class structure. \n",
    "Write the following member functions:\n",
    "- the forward prediction\n",
    "- the cost function computation\n",
    "- the gradient computation\n",
    "- the training algorithm \n",
    "\n",
    "### Learning goals\n",
    "- Understand the foundational steps of machine learning by implementing each of the components\n",
    "- Compare with regression using the Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate noisy training and test data with an 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(765)  # deterministic random seed\n",
    "xTrain = np.random.randn(80)\n",
    "yTrain = 2 * xTrain + 3 + np.random.randn(80)\n",
    "\n",
    "xTest = np.random.randn(20)\n",
    "yTest = 2 * xTest + 3 + np.random.randn(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition in `forward`: $\\hat{y}=wx+b$ \n",
    "\n",
    "Cost function: $C(\\boldsymbol{w},b)=\\frac1{m_\\mathcal{D}}\\sum_{i=1}^{m_\\mathcal{D}}(\\tilde{y}_i-(\\boldsymbol{w}^\\mathsf{T}\\tilde{x}_i+b))^2$\n",
    "\n",
    "Gradient of weights: $\\frac{\\partial C}{\\partial w} =\\frac{1}{m_{\\mathcal{D}}}\\sum_{i=1}^{m_{\\mathcal{D}}}-2\\tilde{x}_{i}\\left(\\tilde{y}_{i}-(w\\tilde{x}_{i}+b)\\right)$\n",
    "\n",
    "Gradient of biases: $\\frac{\\partial C}{\\partial b} =\\frac{1}{m_{\\mathcal{D}}}\\sum_{i=1}^{m_{\\mathcal{D}}}-2\\left(\\tilde{y}_{i}-(w\\tilde{x}_{i}+b)\\right)$\n",
    "\n",
    "Training update steps:\n",
    "$w\\leftarrow w-\\alpha\\frac{\\partial C}{\\partial w} \\\\\n",
    "b\\leftarrow b-\\alpha\\frac{\\partial C}{\\partial b}$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.weight = 0\n",
    "        self.bias = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.weight * x + self.bias\n",
    "        return y\n",
    "\n",
    "    def costFunction(self, x, y):\n",
    "        cost = np.mean((self.forward(x) - y) ** 2)\n",
    "        return cost\n",
    "\n",
    "    def gradient(self, x, y):\n",
    "        gradientWeight = np.mean((2 * (self.forward(x) - y) * x))\n",
    "        gradientBias = np.mean((2 * (self.forward(x) - y)))\n",
    "        return gradientWeight, gradientBias\n",
    "\n",
    "    def train(self, epochs, lr, xTrain, yTrain, xTest, yTest):\n",
    "        for epoch in range(epochs):\n",
    "            costTrain = self.costFunction(xTrain, yTrain)\n",
    "            costTest = self.costFunction(xTest, yTest)\n",
    "\n",
    "            # Update step\n",
    "            gradientWeight, gradientBias = self.gradient(xTrain, yTrain)\n",
    "            self.weight -= lr * gradientWeight\n",
    "            self.bias -= lr * gradientBias\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                string = \"Epoch: {}/{}\\t\\tTraining cost = {:.2e}\\t\\tValidation cost = {:.2e}\"\n",
    "                print(string.format(epoch, epochs, costTrain, costTest))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lr = 5e-2\n",
    "epochs = 101\n",
    "\n",
    "model = LinearRegression()\n",
    "model.train(epochs, lr, xTrain, yTrain, xTest, yTest)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "yTrainPred = model.forward(xTrain)  # not visualized\n",
    "yTestPred = model.forward(xTest)  # not visualized\n",
    "\n",
    "# Draw predictor between min and max x values of Testset\n",
    "x = np.linspace(np.min(xTest), np.max(xTest), 100)\n",
    "yPred = model.forward(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.scatter(xTest, yTest, color=\"r\", label=\"testing data\")\n",
    "ax.scatter(xTrain, yTrain, color=\"k\", label=\"training data\")\n",
    "ax.plot(x, yPred, \"b\", label=\"prediction\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare learned model with normal equations \n",
    "print('Model Bias, b = ', model.bias)\n",
    "print('Model Weight, w = ', model.weight)\n",
    "\n",
    "# Compare with Normal equations approach\n",
    "x = np.matrix(xTrain).T  # column vectors\n",
    "y = np.matrix(yTrain).T\n",
    "X = np.hstack([np.ones((x.shape[0], 1)), x])  # augment with 1s\n",
    "\n",
    "theta = np.linalg.inv(X.T * X) * X.T * y\n",
    "\n",
    "print(\"\\nCompare with Normal equation weights (bias and slope):\\n\", theta)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal equations "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = np.matrix(range(4)).T  # X and Y are column vectors by convention \n",
    "y = 2 * x + 3\n",
    "print('x \\n', x)\n",
    "print('y \\n', y)\n",
    "\n",
    "# for multidimensional regression problems, X is (m, n)\n",
    "#  with m rows for the data points and n columns for the features (dimensions) + 1\n",
    "X = np.hstack([np.ones((x.shape[0], 1)), x])  # augment with 1s\n",
    "\n",
    "X_transpose_X = X.T * X\n",
    "X_transpose_y = X.T * y\n",
    "theta = np.linalg.inv(X_transpose_X) * X_transpose_y\n",
    "\n",
    "print(\"X.T * X:\\n\", X_transpose_X)\n",
    "print(\"X.T * y:\\n\", X_transpose_y)\n",
    "\n",
    "# Print the weights\n",
    "print(\"Weights (bias and slope):\\n\", theta)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = np.matrix(xTrain).T\n",
    "y = np.matrix(yTrain).T\n",
    "X = np.hstack([np.ones((x.shape[0], 1)), x])  # augment with 1s\n",
    "\n",
    "X_transpose_X = X.T * X\n",
    "X_transpose_y = X.T * y\n",
    "theta = np.linalg.inv(X_transpose_X) * X_transpose_y\n",
    "\n",
    "# Print the weights\n",
    "print(\"Weights (bias and slope):\\n\", theta)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
